{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The structure of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four sections of the notebook:\n",
    "\n",
    "* Services: command line, modules, logging\n",
    "* Global variables\n",
    "* Calculations\n",
    "* Functions and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for Tobias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of action:\n",
    "\n",
    "* Run \"Services\" (section 2)\n",
    "* Run the \"functions and tools\" section (section 5)\n",
    "* Input the global variables - the couplings, the size, etc (section 3.1)\n",
    "* Run theta calculator (section 4.1)\n",
    "\n",
    "(run all the cells inside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "from scipy import optimize\n",
    "from functools import reduce\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugging_mode=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(phrase, display_outside_debugging_mode=False):\n",
    "    '''\n",
    "    phrase - fstring describing the message\n",
    "    display_outside_debugging_mode - boolean, explaining whether this line should be printed outside debugging mode\n",
    "    '''\n",
    "    if ( (debugging_mode==True) | (display_outside_debugging_mode) ):\n",
    "        print(phrase)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting global variables from Tobias-style input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "J=0.2\n",
    "\n",
    "#PT orders that you want to approximate with your initialization\n",
    "\n",
    "max_PT_order=4\n",
    "\n",
    "spin_amount=4\n",
    "\n",
    "input_couplings=[['X1X2',0.2],['X2X3',0.2],['X3X4',0.2]]\n",
    "\n",
    "# input_generators=['Y1X2','Y2X3','Y3X4','Y1X3','Y2X4', 'Y1X4' , 'Y1X2X3X4']\n",
    "input_generators=['Y1X2','Y2X3','Y3X4','Y1X3','Y2X4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boring calculations and conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "computational_states=[list(computational_state) for computational_state in (itertools.product(*[[0,1] for spin in range(spin_amount)]))]\n",
    "\n",
    "coupling_string_list=[]\n",
    "\n",
    "coupling_strength_list=[]\n",
    "\n",
    "for coupling in input_couplings:\n",
    "\n",
    "    Tobias_coupling_string=coupling[0]\n",
    "    \n",
    "    coupling_strength=coupling[1]\n",
    "    \n",
    "    assert(coupling_strength==J)\n",
    "\n",
    "    processed_coupling_string=[[Tobias_coupling_string[2*symbol_id], eval(Tobias_coupling_string[2*symbol_id+1])]\n",
    "          for symbol_id in range(len(Tobias_coupling_string)//2)]\n",
    "\n",
    "    Yaroslav_coupling_string=['I' for spin in range(spin_amount)]\n",
    "\n",
    "    for sub in processed_coupling_string:\n",
    "\n",
    "        Yaroslav_coupling_string[sub[1]-1]=sub[0]\n",
    "    \n",
    "    coupling_string_list+=[Yaroslav_coupling_string]\n",
    "    \n",
    "    coupling_strength_list+=[coupling_strength]\n",
    "    \n",
    "\n",
    "generator_string_list=[]\n",
    "\n",
    "for Tobias_generator_string in input_generators:\n",
    "\n",
    "\n",
    "    processed_generator_string=[[Tobias_generator_string[2*symbol_id], eval(Tobias_generator_string[2*symbol_id+1])]\n",
    "          for symbol_id in range(len(Tobias_generator_string)//2)]\n",
    "\n",
    "    Yaroslav_generator_string=['I' for spin in range(spin_amount)]\n",
    "\n",
    "    for sub in processed_generator_string:\n",
    "\n",
    "        Yaroslav_generator_string[sub[1]-1]=sub[0]\n",
    "    \n",
    "    generator_string_list+=[Yaroslav_generator_string]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "generator_to_theta_dictionary=[[i] for i in range(len(input_generators))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_generators=generator_string_list\n",
    "\n",
    "couplings=coupling_string_list\n",
    "\n",
    "couplings_amount=len(couplings)\n",
    "\n",
    "number_of_thetas=len(unitary_generators)\n",
    "\n",
    "generator_to_theta_dictionary=[[i] for i in range(len(unitary_generators))]\n",
    "\n",
    "assert tuple(sorted([theta for generator_thetas in generator_to_theta_dictionary for theta in generator_thetas])\n",
    "            ) == tuple(range(number_of_thetas))\n",
    "\n",
    "assert len(generator_to_theta_dictionary)==number_of_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that the conversion went well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Y', 'X', 'I', 'I'], ['I', 'Y', 'X', 'I'], ['I', 'I', 'Y', 'X'], ['Y', 'I', 'X', 'I'], ['I', 'Y', 'I', 'X']] \n",
      " [['X', 'X', 'I', 'I'], ['I', 'X', 'X', 'I'], ['I', 'I', 'X', 'X']]\n"
     ]
    }
   ],
   "source": [
    "print(generator_string_list, '\\n', coupling_string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up theta-equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 spins\n",
    "3 first order diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation_initialize (PT_mode):\n",
    "    \n",
    "    C_series=normalize_C_dictionary(unnormalized_C_dictionary())\n",
    "\n",
    "    eq_adapted_C_series=eq_adapt_C_series(C_series, PT_mode)\n",
    "\n",
    "    theta_k_variable_list, f_theta_set_for_eq = f_theta_set_function(PT_mode)\n",
    "\n",
    "    f_dict_for_eq = f_theta_to_K_s_dict(f_theta_set_for_eq)\n",
    "\n",
    "    list_of_equations=list(eq_adapted_C_series)\n",
    "    \n",
    "    for key in f_dict_for_eq:\n",
    "    \n",
    "        if key in eq_adapted_C_series:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            eq_adapted_C_series[key]=0\n",
    "        \n",
    "    for key in eq_adapted_C_series:\n",
    "\n",
    "        if key in f_dict_for_eq:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            f_dict_for_eq[key]={}      \n",
    "    \n",
    "    return(eq_adapted_C_series, theta_k_variable_list, f_theta_set_for_eq, f_dict_for_eq, list_of_equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_mode='scalar'\n",
    "\n",
    "eq_adapted_C_series, theta_k_variable_list, f_theta_set_for_eq, f_dict_for_eq, list_of_equations = equation_initialize (PT_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "equation_debugging=False\n",
    "\n",
    "log('the variables are:', equation_debugging)\n",
    "\n",
    "for variable in theta_k_variable_list:\n",
    "    \n",
    "    log(f'{variable}', equation_debugging)\n",
    "    \n",
    "log('the theta-side of the equation is:', equation_debugging)\n",
    "\n",
    "for equation in f_dict_for_eq:\n",
    "    \n",
    "    log(f'{equation}: {f_dict_for_eq[equation]}', equation_debugging)\n",
    "\n",
    "log('the C-side of the equation is:', equation_debugging)\n",
    "\n",
    "for equation in eq_adapted_C_series:\n",
    "    \n",
    "    log(f'{equation}: {eq_adapted_C_series[equation]}', equation_debugging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the equations for thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 3.399350881576538\n",
      " [ 2.14687118e-05  2.49975360e-01  0.00000000e+00 -1.65080610e-12\n",
      "  0.00000000e+00  4.39290989e-04  0.00000000e+00  0.00000000e+00\n",
      " -1.86513202e-01  2.14654285e-05 -4.70295073e-04  0.00000000e+00\n",
      "  2.49945536e-01 -1.87457786e-01  2.50023554e-01  0.00000000e+00\n",
      " -6.49441277e-05 -1.65080610e-12  0.00000000e+00  0.00000000e+00] [4.71073797e-06 4.92808731e-06 1.08928060e-05 7.90990984e-07\n",
      " 1.37941181e-06 5.55425201e-07 3.94610453e-05 3.31880504e-04\n",
      " 4.12896587e-04 8.16413758e-05 4.98094294e-04 2.28249985e-05\n",
      " 2.77641081e-07 1.62509656e-05 2.29398075e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00] \n",
      " The equations are solved with precision: \n",
      " 5.384280289059716e-07\n"
     ]
    }
   ],
   "source": [
    "def equation_system(theta_k_values):\n",
    "    \n",
    "#     For some reason ignoring the J**K weight during the optimization is sometimes beneficial from the perspective of the\n",
    "#     _weighted_ function. I will comment this part out for now, but we may look at it in closer detail later.\n",
    "    \n",
    "#     list_of_eq_values=[np.abs(theta_function(theta_k_values, f_dict_for_eq[equation], theta_k_variable_list)\n",
    "#                  - eq_adapted_C_series[equation])  \n",
    "#                        for equation in list_of_equations]\n",
    "    \n",
    "#   \"eval(re.search('K = \\[(.+?)\\]',equation).group(1))\" is the value of K in the equation\n",
    "    \n",
    "    list_of_eq_values=[np.abs(theta_function(theta_k_values, f_dict_for_eq[equation], theta_k_variable_list)\n",
    "                 - eq_adapted_C_series[equation])  * (J**eval(re.search('K = \\[(.+?)\\]',equation).group(1)) )\n",
    "                       for equation in list_of_equations]\n",
    "    \n",
    "    if len(list_of_equations)<len(theta_k_variable_list):\n",
    "        list_of_eq_values+=[0 for additional_equation in range(len(theta_k_variable_list)-len(list_of_equations))]\n",
    "    \n",
    "    log(f'list_of_eq_values={list_of_eq_values}')\n",
    "    \n",
    "    return(np.array(list_of_eq_values, dtype='float'))\n",
    "\n",
    "stopwatch=time.time()\n",
    "\n",
    "theta_k_values=optimize.minimize(lambda theta: sum(equation_system(theta)**2), np.array([0 for k_theta in theta_k_variable_list])).x\n",
    "\n",
    "# theta_k_values=optimize.leastsq(equation_system, np.array([0 for k_theta in theta_k_variable_list]))[0]\n",
    "\n",
    "print(f'time elapsed: {time.time()-stopwatch}\\n', theta_k_values, equation_system(theta_k_values), '\\n The equations are solved with precision: \\n', sum(equation_system(theta_k_values)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_values=[0 for theta_label in range(len(unitary_generators))]\n",
    "\n",
    "for contribution_number in range(len(theta_k_variable_list)):\n",
    "    \n",
    "    contribution_label=theta_k_variable_list[contribution_number]\n",
    "    \n",
    "    theta_index=contribution_label[0]\n",
    "    \n",
    "    degree_of_PT=contribution_label[1][0]\n",
    "    \n",
    "    contribution_value=theta_k_values[contribution_number]\n",
    "\n",
    "    theta_values[theta_index]+=contribution_value*J**degree_of_PT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's the list of initialization thetas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hamiltonian diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hamiltonian definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def single_body_terms():\n",
    "    \n",
    "    term_strings=[['Z' if spin_label==term_spin_label else 'I' for spin_label in range(spin_amount)] for term_spin_label in range(spin_amount)]\n",
    "    \n",
    "    return(sum([-1.*operator_from_pauli_string(term) for term in term_strings]))\n",
    "\n",
    "\n",
    "def coupling_terms(J):\n",
    "    \n",
    "    return(sum([J*operator_from_pauli_string(term) for term in couplings]))\n",
    "\n",
    "def H(J):\n",
    "    \n",
    "    return(single_body_terms()+coupling_terms(J))\n",
    "\n",
    "\n",
    "def GS(J):\n",
    "\n",
    "    GS_E=np.linalg.eigh(H(J))[0][0]\n",
    "\n",
    "    GS_WF=np.linalg.eigh(H(J))[1].T[0]\n",
    "              \n",
    "    return(GS_E, GS_WF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.plot([np.linalg.eigh(H(J)/(1+np.abs(J)))[0][0:4] for J in np.linspace(-10,10,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# J=-0.5\n",
    "\n",
    "# plt.plot([np.log(abs(wavefunction_from_PT_series (normalized_C_dictionaries[PT_order], J) @ H(J) @ wavefunction_from_PT_series (normalized_C_dictionaries[PT_order], J) - GS(J)[0])/abs(GS(J)[0]))  for PT_order in range(max_PT_order)])\n",
    "\n",
    "# plt.plot([np.log(abs(1-abs(wavefunction_from_PT_series (normalized_C_dictionaries[PT_order], J)@GS(J)[1] ))) for PT_order in range(max_PT_order)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.plot([np.log(abs(wavefunction_from_PT_series (normalized_C_dictionaries[max_PT_order], J) @ wavefunction_from_PT_series (normalized_C_dictionaries[max_PT_order], J)))  for max_PT_order in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tools and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## General tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Combinatorics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def partitioning (n):\n",
    "    '''\n",
    "    Creates all possible partitions of an integer n, as a list of lists\n",
    "    '''\n",
    "    partitions=[[n]]\n",
    "    \n",
    "\n",
    "    \n",
    "    while partitions[-1][0]>1:\n",
    "    \n",
    "        partition=partitions[-1]\n",
    "\n",
    "        '''\n",
    "        Finding the rightmost non-one, reducing it by one:\n",
    "        '''\n",
    "            \n",
    "        for k in range(len(partition)):\n",
    "\n",
    "            if partition[k]>1:\n",
    "                hit_k=k\n",
    "\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        hit_p=partition[hit_k]-1\n",
    "\n",
    "        rest=sum(partition[hit_k+1:])+1\n",
    "        \n",
    "        '''\n",
    "        Stacking up the rest:\n",
    "        '''\n",
    "        \n",
    "        assemble=[hit_p for i in range(rest//hit_p) ]\n",
    "\n",
    "        if rest-sum(assemble)!=0:\n",
    "            assemble+=[rest-sum(assemble)]\n",
    "        \n",
    "        '''\n",
    "        Gathering up the new partition:\n",
    "        '''\n",
    "        \n",
    "        partitions+=[partition[:hit_k]+[hit_p]+assemble]\n",
    "        \n",
    "    \n",
    "\n",
    "    return(partitions)\n",
    "\n",
    "def fill_the_list(the_list, full_length, filler=0):\n",
    "    \n",
    "    if len(the_list)<=full_length:\n",
    "        return(the_list+[0 for iterator in range(full_length-len(the_list))])\n",
    "    else:\n",
    "        return(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### k vectors, couplings and generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def list_of_Ks_from_PT_order(PT_mode='vector'):\n",
    "    \n",
    "    \n",
    "    if PT_mode=='vector':\n",
    "        \n",
    "        list_of_Ks=[]\n",
    "\n",
    "        for mod_K in range(1,max_PT_order+1):\n",
    "            log(f'list_of_Ks addition={list(partitioning(mod_K))}')\n",
    "            list_of_Ks+=list(partitioning(mod_K))\n",
    "\n",
    "        list_of_Ks=[fill_the_list(K, couplings_amount) for K in list_of_Ks if fill_the_list(K,couplings_amount)!=None]\n",
    "\n",
    "        '''\n",
    "        including all permutations of the Ks:\n",
    "        '''\n",
    "\n",
    "        list_of_Ks=[list(K) for K in list(set(reduce(lambda x, y: x+y, [list(itertools.permutations(K_lexic)) for K_lexic in list_of_Ks])))]\n",
    "\n",
    "        list_of_Ks=sorted(list_of_Ks, key = lambda K: sum(K))\n",
    "        \n",
    "    elif PT_mode=='scalar':\n",
    "        \n",
    "        list_of_Ks=[[PT_order] for PT_order in range(1,max_PT_order+1)]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        raise Exception('Unknown PT_mode!')\n",
    "        \n",
    "    return(list_of_Ks)\n",
    "\n",
    "def k_to_couplings(k):\n",
    "    \n",
    "    '''\n",
    "    Assumes that the couplings are commuting Paulis, and implicitly that only one coupling i has k_i%2==1\n",
    "    \n",
    "    Returns a list of coupling labels as integers from 1 to N_c\n",
    "    '''\n",
    "    \n",
    "    k=list(k)\n",
    "    \n",
    "    return([coupling_label for coupling_label in range(len(k)) if k[coupling_label]%2==1])\n",
    "\n",
    "def pauli_strings_from_couplings_list(coupling_labels):\n",
    "    \n",
    "    '''\n",
    "    Returns a list of pauli strings corresponding to a list of coupling labels\n",
    "    \n",
    "    uses global variable 'couplings'\n",
    "    '''\n",
    "    \n",
    "    log(f'pauli_strings_from_couplings_list: \\n The coupling labels are: \\n {coupling_labels}; \\n The couplings are: \\n {couplings}')\n",
    "    \n",
    "    return([couplings[coupling_label] for coupling_label in coupling_labels])\n",
    "\n",
    "\n",
    "def k_to_generator(k):\n",
    "    \n",
    "    '''\n",
    "    Assuming odd-even logic in the couplings. \n",
    "    k is either list or a numpy array\n",
    "    '''\n",
    "    \n",
    "    k=list(k)\n",
    "    \n",
    "    for element in k:\n",
    "        if element%2==1:\n",
    "            return k.index(element)\n",
    "        \n",
    "    print('Didn\"t find a generator for k!')\n",
    "    \n",
    "    return(None)\n",
    "\n",
    "def theta_to_generator(theta_label):\n",
    "    \n",
    "    for thetas_per_generator in generator_to_theta_dictionary:\n",
    "    \n",
    "        if theta_label in thetas_per_generator:\n",
    "        \n",
    "            return(generator_to_theta_dictionary.index(thetas_per_generator))\n",
    "    \n",
    "    raise Exception('Wrong input: nonexistent theta!')\n",
    "\n",
    "def pauli_strings_from_generator_list(generator_list):\n",
    "    return([unitary_generators[generator_label] for generator_label in generator_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pauli action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def operator_from_pauli_string(string):\n",
    "    \n",
    "    single_qubit_operator_list=[]\n",
    "    \n",
    "    for element in string:\n",
    "        if element=='X':\n",
    "            single_qubit_operator_list+=[np.array([[0,1],[1,0]])]\n",
    "        elif element=='Y':\n",
    "            single_qubit_operator_list+=[np.array([[0,-1j],[0,1j]])]\n",
    "        elif element=='Z':\n",
    "            single_qubit_operator_list+=[np.array([[1,0],[0,-1]])]\n",
    "        elif element=='I':\n",
    "            single_qubit_operator_list+=[np.array([[1,0],[0, 1]])] \n",
    "        else:\n",
    "            raise('Non-pauli input')\n",
    "    \n",
    "    return(reduce(np.kron, single_qubit_operator_list))\n",
    "\n",
    "def single_pauli_action(pauli, spin):\n",
    "    \n",
    "    if pauli=='X':\n",
    "        return(np.mod(spin+1,2), 1)\n",
    "    elif pauli=='Y':\n",
    "        return(np.mod(spin+1,2), 1j*(-1)**spin)\n",
    "    elif pauli=='Z':\n",
    "        return(spin, (-1)**spin)\n",
    "    elif pauli=='I':\n",
    "        return(spin, 1)\n",
    "    else:\n",
    "        print('wrong pauli!')\n",
    "        return(None)\n",
    "\n",
    "def pauli_string_action(pauli_string, spins_and_prefactor):\n",
    "    \n",
    "    '''\n",
    "    Given a pauli_string (label) and a computation basis state+prefactor, \n",
    "    returns a new computational state with a new prefactor\n",
    "    \n",
    "    spins_and_prefactors=[integer list, complex number]\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    spins=spins_and_prefactor[0]\n",
    "    \n",
    "    assert len(pauli_string)==len(spins)\n",
    "    \n",
    "    new_spins_and_prefactor=[single_pauli_action(pauli_string[spin_number], spins[spin_number]) for spin_number in range(len(spins))]\n",
    "    \n",
    "    return([[element[0] for element in new_spins_and_prefactor], \n",
    "                         spins_and_prefactor[1]*reduce(lambda x,y: x*y, [element[1] for element in new_spins_and_prefactor])])\n",
    "\n",
    "\n",
    "def threaded_pauli_strings_action(pauli_strings,spins_and_prefactor):\n",
    "    return(reduce(lambda s_and_p, p_str: pauli_string_action(p_str, s_and_p), [spins_and_prefactor]+pauli_strings) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## PT series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Dyson elementaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def s_of_k(K):\n",
    "    \n",
    "    log(f's_of_k:\\n K={K},\\n k_to_couplings(K) = {k_to_couplings(K)}')\n",
    "    \n",
    "    return(threaded_pauli_strings_action(pauli_strings_from_couplings_list(k_to_couplings(K)), [[0 for spin in range(spin_amount)],1])[0])\n",
    "\n",
    "def E0_of_s(s):\n",
    "    return( sum([-1*(-1)**spin_value for spin_value in s]))\n",
    "\n",
    "def K_trivial_state_check(K):\n",
    "    return( reduce(lambda A, B: A and B, [s==0 for s in s_of_k(K)] ) and not reduce(lambda A, B: A and B, [Ki==0 for Ki in K] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### C-series manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def C_mult(C1, C2):\n",
    "    return([C1[0]+C2[0], C1[1]*C2[1]])\n",
    "\n",
    "def PT_cutoff(C_series):\n",
    "    \n",
    "    return([C for C in C_series if np.sum(C[0])<=max_PT_order])\n",
    "\n",
    "def C_series_add(C_series_1, C_series_2):\n",
    "    \n",
    "    the_sum=C_series_1+C_series_2\n",
    "    \n",
    "    K_set={tuple(C[0]) for C in the_sum}\n",
    "\n",
    "    \n",
    "#     log(f'add={add}')\n",
    "#     log(f'K_set={K_set}')\n",
    "    \n",
    "    the_sum=[[np.array(K), sum([C[1] for C in the_sum if tuple(C[0])==K])] for K in K_set]\n",
    "    \n",
    "    the_sum=sorted(the_sum, key=lambda C: np.sum(C[0]))\n",
    "    \n",
    "    return(the_sum)\n",
    "\n",
    "def C_series_mult(C_series_1, C_series_2):\n",
    "    \n",
    "    the_product=[[C1[0]+C2[0], C1[1]*C2[1]] for C1, C2 in list(itertools.product(C_series_1, C_series_2))]\n",
    "    \n",
    "    K_set={tuple(C[0]) for C in the_product}\n",
    "\n",
    "    \n",
    "#     log(f'mult={mult}')\n",
    "#     log(f'K_set={K_set}')\n",
    "    \n",
    "    the_product=[[np.array(K), sum([C[1] for C in the_product if tuple(C[0])==K])] for K in K_set]\n",
    "    \n",
    "    the_product=sorted(the_product, key=lambda C: np.sum(C[0]))\n",
    "    \n",
    "    return(the_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Dyson calculus: unnormalized C-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def unnormalized_C_dictionary():\n",
    "    \n",
    "    list_of_Ks=list_of_Ks_from_PT_order()\n",
    "    \n",
    "    the_C_list=[[np.array([0 for coupling in range(couplings_amount)]), 1]]\n",
    "    the_C_dictionary={str(a_C[0].tolist()): a_C[1] for a_C in the_C_list}\n",
    "\n",
    "    delta_betas=[np.array(delta_beta) for delta_beta in np.eye(couplings_amount, dtype='int').tolist()]\n",
    "\n",
    "    for K_as_a_list in [K for K in list_of_Ks if ((not K_trivial_state_check(K)) and (sum(K)<=max_PT_order))]:\n",
    "                \n",
    "        \n",
    "        K=np.array(K_as_a_list)\n",
    "\n",
    "        log(f'K={K}')\n",
    "\n",
    "        K_betas=[K-delta_betas[beta] for beta in range(couplings_amount) \n",
    "                 if K[beta]>0 and not K_trivial_state_check(K-delta_betas[beta])]\n",
    "\n",
    "        C_betas=[the_C_dictionary[str(K_beta.tolist())] for K_beta in K_betas]\n",
    "\n",
    "        log(f'K_betas={K_betas}')\n",
    "\n",
    "        k_primes=[np.array(k_prime) for k_prime in list(itertools.product(*[list(range(Ki+1)) for Ki in K]))]\n",
    "\n",
    "        k_primes=[k_prime for k_prime in k_primes if (K_trivial_state_check(k_prime))]\n",
    "\n",
    "        k_primes_betas=[[k_prime-delta_betas[beta] for beta in range(couplings_amount) if k_prime[beta]>0] for k_prime in k_primes]\n",
    "\n",
    "\n",
    "        log(f'k_primes={k_primes}')\n",
    "        log(f'k_primes_betas={k_primes_betas}')\n",
    "\n",
    "        C_k_prime_beta_sums=[sum([the_C_dictionary[str(k_prime_beta.tolist())] if str(k_prime_beta.tolist()) \n",
    "                                  in the_C_dictionary else 0 for k_prime_beta in k_primes_betas[k_prime_index] ]) \n",
    "                             for k_prime_index in range(len(k_primes))]\n",
    "        \n",
    "        C_k_minus_k_primes=[the_C_dictionary[str((K-k_prime).tolist())] if str((K-k_prime).tolist()) \n",
    "                            in the_C_dictionary else 0 for k_prime in k_primes]\n",
    "      \n",
    "\n",
    "        k_prime_terms=[C_k_prime_beta_sums[k_prime_iterator]*C_k_minus_k_primes[k_prime_iterator] \n",
    "                       for k_prime_iterator in range(len(k_primes))]\n",
    "\n",
    "\n",
    "\n",
    "        log(f'k_primes_terms={k_prime_terms}')\n",
    "\n",
    "        the_C_list+=[[K, (sum(C_betas)-sum(k_prime_terms))/(E0_of_s([0 for spin in range(spin_amount)])\n",
    "                                                            \n",
    "                                                            -E0_of_s(s_of_k(K)))]]\n",
    "\n",
    "        log(f'the_C_list addition = {[K, (sum(C_betas)-sum(k_prime_terms))/(E0_of_s([0,0,0,0])-E0_of_s(s_of_k(K)))]}')\n",
    "\n",
    "\n",
    "\n",
    "        the_C_dictionary={str(a_C[0].tolist()): a_C[1] for a_C in the_C_list}\n",
    "\n",
    "        log(f'current the_C_dictionary = {the_C_dictionary}')\n",
    "\n",
    "\n",
    "    return(the_C_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Normalizing, equation-adapting C-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def C_series_to_Z(C_series):\n",
    "    \n",
    "    C_series_by_comp_state={str(s): [C for C in C_series if s_of_k(C[0])==s] for s in computational_states}\n",
    "    \n",
    "    log(f'C_series_by_comp_state\\n')\n",
    "    for comp_state in C_series_by_comp_state:\n",
    "        log(f'{comp_state}={C_series_by_comp_state[comp_state]}')\n",
    "    \n",
    "    pre_Z=[C_series_mult(C_series_by_comp_state[str(s)], C_series_by_comp_state[str(s)]) for s in computational_states]\n",
    "    \n",
    "    for pre_Z_element in pre_Z:\n",
    "        log(f'pre_Z_element={pre_Z_element}\\n')\n",
    "    \n",
    "    Z=reduce(C_series_add, pre_Z)\n",
    "    \n",
    "    log(f'Z={Z}')\n",
    "    \n",
    "    return(Z)\n",
    "\n",
    "\n",
    "def N_from_Z(Z):\n",
    "    \n",
    "    X=[C_Z for C_Z in Z if np.sum(C_Z[0])!=0]\n",
    "    \n",
    "    alpha=-1/2\n",
    "    \n",
    "    N=[[np.array([0 for coupling in range(couplings_amount)]), 1]]\n",
    "    \n",
    "    expansion_term=[[np.array([0 for coupling in range(couplings_amount)]), 1]]\n",
    "    \n",
    "    for order in range(1, max_PT_order+1):\n",
    "        \n",
    "        expansion_term=[[C[0], C[1]*(alpha-order+1)/order] for C in PT_cutoff(C_series_mult(expansion_term,X))]\n",
    "        N=C_series_add(N,expansion_term)\n",
    "                    \n",
    "        log(f'added to N: {expansion_term}\\n')\n",
    "        log(f'new N: {N}\\n')\n",
    "    \n",
    "    N=sorted(N, key= lambda C: np.sum(C[0]))\n",
    "        \n",
    "    return( PT_cutoff(N) )\n",
    "\n",
    "\n",
    "def normalize_C_dictionary(the_C_dictionary):\n",
    "\n",
    "    the_C_list=[[np.array(eval(key)), the_C_dictionary[key]] for key in the_C_dictionary]\n",
    "\n",
    "    Z=PT_cutoff(C_series_to_Z(the_C_list))\n",
    "\n",
    "    N=N_from_Z(Z)\n",
    "\n",
    "    normalized_C_list=PT_cutoff(C_series_mult(the_C_list, N))\n",
    "\n",
    "    normalized_C_dictionary={str(a_C[0].tolist()): a_C[1] for a_C in normalized_C_list}\n",
    "\n",
    "\n",
    "\n",
    "    return(normalized_C_dictionary)\n",
    "\n",
    "\n",
    "\n",
    "def eq_adapt_C_series(C_series, PT_mode='vector'):\n",
    "    \n",
    "    '''\n",
    "    C_series is assumed to have raw form ({'[0,0,0]': 1, ...}), \n",
    "    but the output is in the equation-ready form ({'K = {[K]}, s = {s}': ...})\n",
    "    '''\n",
    "    \n",
    "    adapted_C_series = dict()\n",
    "\n",
    "    for K in C_series:\n",
    "        \n",
    "        if K == str([0 for coupling in range(couplings_amount)]):\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        if PT_mode=='scalar':\n",
    "        \n",
    "            C_K_label=f'K = {[sum(eval(K))]}, s = {s_of_k(eval(K))}'\n",
    "            \n",
    "        elif PT_mode=='vector':\n",
    "            \n",
    "            C_K_label=f'K = {K}, s = {s_of_k(eval(K))}'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            raise Exception('Unknown PT_mode!')\n",
    "\n",
    "        if C_K_label in adapted_C_series:\n",
    "\n",
    "            adapted_C_series[C_K_label] += C_series[K]\n",
    "\n",
    "        else:\n",
    "\n",
    "            adapted_C_series.update({C_K_label: C_series[K]})\n",
    "\n",
    "        log(f'included the value of {C_K_label} type into the series: {C_series[K]}')\n",
    "\n",
    "    return (adapted_C_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Wavefunction representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def wavefunction_from_PT_series (normalized_C_dictionary, J):\n",
    "    \n",
    "    computational_states=[ [[np.array([1 if s==label else 0 for label in range(2)]) for s in s_string], coef] for s_string, coef in [[s_of_k(eval(K)), normalized_C_dictionary[K]*J**sum(eval(K))] for K in normalized_C_dictionary]]\n",
    "    \n",
    "    wavefunction=sum([coef*reduce(np.kron, computational_state) for computational_state, coef in computational_states])\n",
    "    \n",
    "    wavefunction=wavefunction/np.linalg.norm(wavefunction)\n",
    "    \n",
    "    return(wavefunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# C_coefficients={'[0, 2, 0]': -1/32, '[0, 0, 2]': -1/32, '[2, 0, 0]': -1/32, '[1, 1, 0]': 1/8, '[0, 1, 1]': 1/8, '[1, 0, 1]': 1/16, '[0, 0, 1]': -1/4, '[1, 0, 0]': -1/4, '[0, 1, 0]': -1/4}\n",
    "# C_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## f-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### $\\vec{K}(f)$, $\\vec{N}(f)$ and $\\Theta(f)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def PT_order_from_f_theta(f_theta):\n",
    "    return(list(sum([np.array(k_theta[1]) for k_theta in f_theta])))\n",
    "\n",
    "def f_theta_to_pauli_strings(f_theta):\n",
    "    \n",
    "    return(pauli_strings_from_generator_list([theta_to_generator(k_theta[0]) for k_theta in f_theta]))\n",
    "\n",
    "def comp_state_from_f_theta(f_theta):\n",
    "    \n",
    "    generators_action=threaded_pauli_strings_action(f_theta_to_pauli_strings(f_theta),\n",
    "                                                    [[0 for spin_number in range(spin_amount)], 1j**len(f_theta)])\n",
    "    \n",
    "    return(generators_action)\n",
    "\n",
    "def multiplicities_factorials(f_theta):\n",
    "    counts=[]\n",
    "    for element in f_theta:\n",
    "        counts+=[f_theta.count(element)]\n",
    "        f_theta=list(filter(lambda element_prime: element_prime!=element, f_theta))\n",
    "\n",
    "    return(reduce(mul, [math.factorial(count) for count in counts]) )\n",
    "    \n",
    "def product_function(theta_ks, f_theta, theta_k_variable_list):\n",
    "    \n",
    "    theta_k_indices=[theta_k_variable_list.index(k_theta) for k_theta in f_theta]\n",
    "    \n",
    "    prefactor=comp_state_from_f_theta(f_theta)[1]/multiplicities_factorials(f_theta)\n",
    "    \n",
    "    return(reduce(mul, [theta_ks[index] for index in theta_k_indices] )* prefactor)\n",
    "\n",
    "def theta_function(theta_ks, fs_theta, theta_k_variable_list):\n",
    "\n",
    "    return(sum(product_function(theta_ks, f, theta_k_variable_list) for f in fs_theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Combinatoric tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def odd_count(the_list):\n",
    "    return(len([element for element in the_list if element%2==1]))\n",
    "\n",
    "def odd_count_equals_one(theta_k):\n",
    "    return(odd_count(theta_k[1])==1)\n",
    "    \n",
    "def theta_to_k_correspondence(theta_k):\n",
    "    return(k_to_generator(theta_k[1])==theta_to_generator(theta_k[0]))\n",
    "\n",
    "def f_theta_PT_filter(f_theta):\n",
    "    return(sum([sum(theta_k[1]) for theta_k in f_theta])<=max_PT_order)\n",
    "\n",
    "\n",
    "def theta_k_filter(theta_k, PT_mode):\n",
    "    \n",
    "    if PT_mode=='vector':\n",
    "        return(odd_count_equals_one(theta_k) and theta_to_k_correspondence(theta_k))\n",
    "    \n",
    "    elif PT_mode=='scalar':\n",
    "        return(odd_count_equals_one(theta_k))\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unknown PT_mode!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$\\theta^\\alpha$ - a parameter of a single generator\n",
    "\n",
    "\\theta^\\alpha = \\sum_k \\theta^\\alpha_k J^k\n",
    "\n",
    "e^ i \\theta T\n",
    "\n",
    "\n",
    "\\Psi = e^i\\theta T* ... * ... * \\ket{0000} \n",
    "\n",
    "$C_\\vec{K} + C_\\vec{K'} + C_\\vec{K''}  = # * \\theta^\\alpha_k * \\theta^\\alpha'_k' * ... + \\theta^\\alpha_k * \\theta^\\alpha'_k' * ... , k+k'+..=K, K=|\\vec{K}|=|\\vec{K'}|=|\\vec{K''}|, s(\\vec{K, K', K''}) = s, s(\\alpha,\\alpha') = T^\\alpha T^\\alpha'..{0000} $\n",
    "\n",
    "K=(3,0,0)\n",
    "\n",
    "K'=(1,0,2)\n",
    "\n",
    "K''=(0,0,3)\n",
    "\n",
    "1100\n",
    "\n",
    "theta^\\alpha_(1,0,0)=0\n",
    "\n",
    "T=IYXI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### f list generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The scheme of f_theta creation:\n",
    "\n",
    "* Generate all theta_k, i.e. $\\theta^{\\vec{k}}$ (or $\\theta^{k}$); list as first order terms; remove the apriori bad theta_ks by some appropriate filters\n",
    "* Take a Descartes square of that; throw away the dublicates and all above the PT filter; list as second power terms\n",
    "* Multiply 2nd order by the first order terms; remove the dublicates, do the PT filter; list as third power\n",
    "* Etc, until the power=max PT order. Combine the results together into a full f_theta set\n",
    "* Output the theta_ks and the full set\n",
    "\n",
    "The dictionary corresponding the f_thetas and the K vectors they amount to, is created separately, using $K(f)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f_theta_set_function(PT_mode):\n",
    "    \n",
    "    stopwatch=time.time()\n",
    "    \n",
    "    PT_orders_for_theta=list_of_Ks_from_PT_order(PT_mode)\n",
    "    \n",
    "    log(f'PT_orders_for_theta: {PT_orders_for_theta}')\n",
    "    \n",
    "    theta_k_set=set()\n",
    "\n",
    "    for theta in range(number_of_thetas):\n",
    "        theta_k_set.update([(theta, tuple(a_K)) for a_K in PT_orders_for_theta ])\n",
    "    \n",
    "    log(f'theta_k_set: {theta_k_set}')\n",
    "    \n",
    "#     For TUCC applied to TFIM, it makes sense to remove all even PT orders from theta expansion\n",
    "#     theta_k_set=set(filter(lambda theta_k: theta_k_filter(theta_k, PT_mode), theta_k_set))\n",
    "\n",
    "    log(f'filtered theta_k_set: {theta_k_set}')\n",
    "    \n",
    "    all_f_thetas=set()\n",
    "\n",
    "    new_power_f_thetas=set((theta_k,) for theta_k in theta_k_set)\n",
    "\n",
    "    log(f'new_power_f_thetas: {new_power_f_thetas}')\n",
    "\n",
    "    all_f_thetas.update(new_power_f_thetas)\n",
    "\n",
    "    for theta_power in range(1, max_PT_order+1):   \n",
    "\n",
    "        '''\n",
    "        Simply listing all potential next-power terms\n",
    "        '''\n",
    "\n",
    "        new_power_f_thetas=set(a_product[0]+(a_product[1],) for a_product \n",
    "                               in set(itertools.product(new_power_f_thetas,theta_k_set)) )\n",
    "\n",
    "        log(f'new_power_f_thetas: {new_power_f_thetas}')\n",
    "\n",
    "\n",
    "        '''\n",
    "        Sorting the f_thetas: to avoid dublicates and to order terms for the T-action\n",
    "        '''\n",
    "\n",
    "        new_power_f_thetas=set(tuple(sorted(list(f_theta), key=lambda theta_k: theta_k[0])) for f_theta in new_power_f_thetas)\n",
    "\n",
    "        log(f'sorted new_power_f_thetas: {new_power_f_thetas}')\n",
    "\n",
    "        '''\n",
    "        Filtering out the higher order terms\n",
    "        '''\n",
    "\n",
    "        new_power_f_thetas=set(filter(lambda f_theta: f_theta_PT_filter(f_theta), new_power_f_thetas))\n",
    "\n",
    "        log(f'filtered new_power_f_thetas: {new_power_f_thetas}')\n",
    "\n",
    "        all_f_thetas.update(new_power_f_thetas)\n",
    "\n",
    "        log(f'all_f_thetas: {all_f_thetas}')\n",
    "    \n",
    "    log(f'f_theta_set evaluation completed, time elapsed: {time.time()-stopwatch}')\n",
    "    \n",
    "    return(list(theta_k_set), all_f_thetas)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " ... Adding metadata to the possible f functions: K, or K and s \n",
    "(K can be either vector or scalar, doesn't matter) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f_theta_to_K_dict(the_f_theta_set):\n",
    "    \n",
    "    f_theta_K_dict=dict()\n",
    "    \n",
    "    for f_theta in the_f_theta_set:\n",
    "        \n",
    "        label_for_f_theta = f'K = {str(PT_order_from_f_theta(f_theta))}'\n",
    "        \n",
    "        if label_for_f_theta in f_theta_K_dict:\n",
    "            \n",
    "            f_theta_K_dict[label_for_f_theta].update({f_theta})\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            f_theta_K_dict.update({label_for_f_theta : {f_theta}})\n",
    "       \n",
    "        \n",
    "    return(f_theta_K_dict)\n",
    "\n",
    "def f_theta_to_K_s_dict(the_f_theta_set):\n",
    "    \n",
    "    f_theta_K_s_dict=dict()\n",
    "    \n",
    "    for f_theta in the_f_theta_set:\n",
    "        \n",
    "        K_for_f_theta=PT_order_from_f_theta(f_theta)\n",
    "        \n",
    "        s_for_f_theta=tuple(comp_state_from_f_theta(f_theta)[0])\n",
    "        \n",
    "        label_for_f_theta=f'K = {str(PT_order_from_f_theta(f_theta))}, s = {comp_state_from_f_theta(f_theta)[0]}'\n",
    "        \n",
    "        if label_for_f_theta in f_theta_K_s_dict:\n",
    "            \n",
    "            f_theta_K_s_dict[label_for_f_theta].update({f_theta})\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            f_theta_K_s_dict.update({label_for_f_theta : {f_theta}})\n",
    "       \n",
    "    for K_s in f_theta_K_s_dict:\n",
    "        log(f'{K_s}: {f_theta_K_s_dict[K_s]}')    \n",
    "    \n",
    "    return(f_theta_K_s_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Faster (but more complicated) f list generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Combinatorics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def length_fillter(list_of_lists, max_length):\n",
    "    \n",
    "    '''\n",
    "    Fills the elements of a list of lists with zeros, up to the certain max_length, \n",
    "    and returns None if there are longer elements\n",
    "    '''\n",
    "    \n",
    "    new_list_of_lists=[]\n",
    "    \n",
    "    for a_list in list_of_lists:\n",
    "    \n",
    "        new_list_of_lists+=[fill_the_list(a_list, max_length, 0)]\n",
    "        if new_list_of_lists[-1]==None:\n",
    "            return(None)\n",
    "        \n",
    "    return(new_list_of_lists)\n",
    "\n",
    "\n",
    "    \n",
    "def odd_upon_even_condition(the_list):\n",
    "\n",
    "    return(reduce((lambda x, y: x and y), [len([element for element in sublist if element%2==1])==1 for sublist in the_list]))\n",
    "    \n",
    "def odd_upon_even_filter(lists_of_k):\n",
    "    return([a_list for a_list in lists_of_k if odd_upon_even_condition(a_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_PT_order' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-02cc09d87afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mfs_from_K\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mthe_K\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_PT_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_PT_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     '''\n\u001b[0;32m      3\u001b[0m     \u001b[0mProduces\u001b[0m \u001b[0mall\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mEach\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mrepresented\u001b[0m \u001b[0mby\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mvectors\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mare\u001b[0m \u001b[0mincluded\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_PT_order' is not defined"
     ]
    }
   ],
   "source": [
    "def fs_from_K (the_K, max_PT_order=max_PT_order):\n",
    "    '''\n",
    "    Produces all f-functions such that K(f)=K for a given K-vector\n",
    "    \n",
    "    Each f is represented by a list of k-vectors (tuples) which are included in the f, \n",
    "    with dublicates representing the multiplicities\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    The scheme of the algorithm is as follows:\n",
    "    \n",
    "    first, one considers independent partitions of Ki (elements of K)\n",
    "    \n",
    "    then, these (and zeros) are used as ki for k-vectors; \n",
    "    the number of generators are fixed to be the number of odd ki's\n",
    "    \n",
    "    all k-vectors are produced, as the possible 1-1-1-..-1 correspondences between the available kis\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    partitioned_Ki= list of partitions of K_i for each Ki in K\n",
    "    K_partitions= combinations of partitions of each K_i\n",
    "    '''\n",
    "\n",
    "    partitioned_Ki=[]\n",
    "\n",
    "    log(f\"the_K={K}\")\n",
    "    \n",
    "    for element in the_K:\n",
    "        partitioned_Ki+=[partitioning(element)]\n",
    "\n",
    "    K_partitions=[list(K_partition) for K_partition in itertools.product(*partitioned_Ki)]\n",
    "\n",
    "    \n",
    "    fs_for_K=set()\n",
    "    \n",
    "\n",
    "    for K_partition in K_partitions:\n",
    "\n",
    "        number_of_generators=odd_count([element for sublist in list(K_partition) for element in sublist])\n",
    "\n",
    "        '''\n",
    "        filltered_K_partition - filled with zeros up until the total amount of odds; if not enough odds, throws out the thing\n",
    "        '''\n",
    "        \n",
    "        log(f\"K_partition={K_partition}\")\n",
    "        \n",
    "        \n",
    "        filltered_K_partition=length_fillter(K_partition, number_of_generators)\n",
    "\n",
    "        log(f\"filltered_K_partition={filltered_K_partition}\")\n",
    "        \n",
    "        if filltered_K_partition==None:\n",
    "            continue\n",
    "\n",
    "\n",
    "        '''\n",
    "        generates all possible ways to break the filltered_K_partition into k_i correspondences\n",
    "        '''\n",
    "           \n",
    "        K_partition_permutations=[ [tuple(filltered_K_partition[0])] ]+[list(set(itertools.permutations(element))) for element in filltered_K_partition[1:]]\n",
    "\n",
    "        log(f\"K_partition_permutations={K_partition_permutations}\")\n",
    "        \n",
    "        k_combinations=list( itertools.product(*K_partition_permutations) )\n",
    "\n",
    "        '''\n",
    "        k_combinations_as_lists - possible combinations of k^alpha_i in an f, given a partition of K\n",
    "        '''\n",
    "\n",
    "        k_combinations_transposed=[[tuple(k) for k in list(np.array(ki_combination).T)] for ki_combination in k_combinations]\n",
    "\n",
    "        log(f\"k_combinations={k_combinations} \\nk_combinations_transposed={k_combinations_transposed}\")\n",
    "        \n",
    "        k_combinations_transposed=odd_upon_even_filter(k_combinations_transposed)\n",
    "\n",
    "        log(f\"k_combinations_transposed filtered={k_combinations_transposed}\")\n",
    "        \n",
    "        for element in k_combinations_transposed:\n",
    "            element.sort()\n",
    "\n",
    "        filtered_tuples_of_k=[tuple(list_of_k) for list_of_k in k_combinations_transposed]\n",
    "\n",
    "        fs_for_K.update(filtered_tuples_of_k)\n",
    "\n",
    "        '''\n",
    "        set_of_ks - same as lists_of_k, but a set in terms of tuples, filtered the ones where odd k_i occurs other than twice, \n",
    "                    and the whole tuples never repeat\n",
    "        '''\n",
    "        \n",
    "    return(fs_for_K)\n",
    "\n",
    "\n",
    "def fs_theta_from_fs(fs):\n",
    "    \n",
    "    '''\n",
    "    Produces all f_theta functions, given the f-functions    \n",
    "    '''\n",
    "    \n",
    "    fs_theta=set()\n",
    "    \n",
    "    for f in fs_for_K:\n",
    "        \n",
    "        '''\n",
    "        generate all possible combinations of parameters, corresponding to the list of k's\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        fs_theta_from_f=list(itertools.product(*[\n",
    "            \n",
    "            tuple([(theta_label,k) for theta_label in generator_to_theta_dictionary[k_to_generator(k)] ] ) \n",
    "            \n",
    "            for k in f]))\n",
    "        \n",
    "        \n",
    "        log(f'k-theta distribution:{fs_theta_from_f}')\n",
    "        \n",
    "        '''\n",
    "        sort each final combination according to the order of parameters - \n",
    "        to avoid ambiguity in the def of f_theta and to make the generator product (\"T-action\") well-defined\n",
    "        '''\n",
    "        \n",
    "        fs_theta_from_f=[tuple(sorted(f_theta, key=lambda k_theta: k_theta[0])) for f_theta in fs_theta_from_f]\n",
    "        \n",
    "        log(f'sorted k-theta distribution:{fs_theta_from_f}')\n",
    "        \n",
    "        '''\n",
    "        there may be some duplicates in f_theta, but they are removed when updating:\n",
    "        '''\n",
    "        \n",
    "        fs_theta.update(fs_theta_from_f)\n",
    "        \n",
    "    return(fs_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Generating the fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# log(f'list_of_Ks={list_of_Ks}')\n",
    "\n",
    "# stopwatch=time.time()\n",
    "\n",
    "# all_fs=dict()\n",
    "\n",
    "# all_ks_theta=set()\n",
    "\n",
    "# all_fs_theta=dict()\n",
    "\n",
    "# for K in list_of_Ks_from_PT_order(max_PT_order):\n",
    "\n",
    "#     fs_for_K=fs_from_K(K)\n",
    "    \n",
    "#     all_fs.update({str(K): fs_for_K})\n",
    "    \n",
    "#     fs_theta_for_K=fs_theta_from_fs(fs_for_K)\n",
    "\n",
    "#     for f_theta in fs_theta_for_K:\n",
    "                \n",
    "#         all_ks_theta.update(f_theta)\n",
    "        \n",
    "#     all_fs_theta.update({str(K): fs_theta_for_K})\n",
    "\n",
    "\n",
    "# k_and_theta_list=list(all_ks_theta)            \n",
    "\n",
    "# for K in all_fs_theta:\n",
    "#     log(f'{K}: {all_fs_theta[K]}')\n",
    "\n",
    "# print(time.time()-stopwatch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "229px",
    "width": "286px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "48px",
    "left": "1031px",
    "top": "110.8px",
    "width": "284px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
